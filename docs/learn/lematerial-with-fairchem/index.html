<!doctype html><html lang=en data-bs-theme=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1"><link rel=preload href=../../../fonts/vendor/jost/jost-v4-latin-regular.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=../../../fonts/vendor/jost/jost-v4-latin-500.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=../../../fonts/vendor/jost/jost-v4-latin-700.woff2 as=font type=font/woff2 crossorigin><script src=../../../js/color-mode.86a91f050a481d0a3f0c72ac26543cb6228c770875981c58dcbc008fd3f875c8.js integrity="sha256-hqkfBQpIHQo/DHKsJlQ8tiKMdwh1mBxY3LwAj9P4dcg="></script><link rel=stylesheet href="/main.a44ccbbf77d761971fa5a23d21059c08697dea984cbcb770d89790296097795bec589ba799451ff94f5e7658069c0c6500585c945b6b29df3473a6938ea46561.css" integrity="sha512-pEzLv3fXYZcfpaI9IQWcCGl96phMvLdw2JeQKWCXeVvsWJunmUUf+U9edlgGnAxlAFhclFtrKd80c6aTjqRlYQ==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><base href=../../../docs/learn/lematerial-with-fairchem/><link rel=canonical href=../../../docs/learn/lematerial-with-fairchem/><title>LeMaterial x FAIRChem</title>
<meta name=description content="Train LeMaterial with FAIRChem EquiformerV2 model"><link rel=icon href=../../../favicon.ico sizes=32x32><link rel=icon href=../../../favicon.svg type=image/svg+xml><link rel=apple-touch-icon href=../../../apple-touch-icon.png sizes=180x180 type=image/png><link rel=icon href=../../../favicon-192x192.png sizes=192x192 type=image/png><link rel=icon href=../../../favicon-512x512.png sizes=512x512 type=image/png><link rel=manifest href=../../../manifest.webmanifest><meta property="og:title" content="LeMaterial with FAIRChem"><meta property="og:description" content="LeMaterial with FAIRChem"><meta property="og:type" content="article"><meta property="og:url" content="/docs/learn/lematerial-with-fairchem/"><meta property="og:image" content="/cover.png"><meta property="article:section" content="docs"><meta property="article:published_time" content="2023-09-07T16:04:48+02:00"><meta property="article:modified_time" content="2023-09-07T16:04:48+02:00"><meta property="og:site_name" content="LeMaterial"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="/cover.png"><meta name=twitter:title content="LeMaterial with FAIRChem"><meta name=twitter:description content="LeMaterial with FAIRChem"><meta name=twitter:site content="@getdoks"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"/","name":"Le Material","position":1},{"@type":"ListItem","item":"/docs/","name":"About the Project","position":2},{"@type":"ListItem","item":"/docs/learn/","name":"Tutorials","position":3},{"@type":"ListItem","name":"Le Material With Fairchem","position":4}]}</script></head><body class="single section docs" data-bs-spy=scroll data-bs-target=#toc data-bs-root-margin="0px 0px -60%" data-bs-smooth-scroll=true tabindex=0><div class=sticky-top><header class="navbar navbar-expand-lg"><div class=container-lg><a class="navbar-brand me-auto me-lg-3" href=../../../>LeMaterial</a>
<button type=button id=searchToggleMobile class="btn btn-link nav-link mx-2 d-lg-none" aria-label="Search website">
<svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
</button>
<button class="btn btn-link d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasNavSection aria-controls=offcanvasNavSection aria-label="Open section navigation menu"><svg class="icon icon-tabler icon-tabler-dots-vertical" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 12m-1 0a1 1 0 102 0 1 1 0 10-2 0"/><path d="M12 19m-1 0a1 1 0 102 0 1 1 0 10-2 0"/><path d="M12 5m-1 0a1 1 0 102 0 1 1 0 10-2 0"/></svg></button><div class="offcanvas offcanvas-start d-lg-none" tabindex=-1 id=offcanvasNavSection aria-labelledby=offcanvasNavSectionLabel><div class=offcanvas-header><h5 class=offcanvas-title id=offcanvasNavSectionLabel>Docs</h5><button type=button class="btn btn-link nav-link p-0 ms-auto" data-bs-dismiss=offcanvas aria-label=Close><svg class="icon icon-tabler icon-tabler-x" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18 6 6 18"/><path d="M6 6l12 12"/></svg></button></div><div class=offcanvas-body><aside class="doks-sidebar mt-n3"><nav id=doks-docs-nav aria-label="Tertiary navigation"><nav class="section-nav docs-links"><ul class=list-unstyled><li><a href=../../../docs/reading-group/>Reading Group</a></li><li><details open><summary>About</summary><ul class="list-unstyled list-nested"><li><a href=../../../docs/about/the-mission/>The mission</a></li><li><a href=../../../docs/about/datasets/>Datasets</a></li><li><a href=../../../docs/about/citations/>Citations</a></li><li><a href=../../../docs/about/how-to-join/>How to join?</a></li><li><a href=../../../docs/about/code-of-conduct/>Code of Conduct</a></li></ul></details></li><li><details open open><summary>Tutorials</summary><ul class="list-unstyled list-nested"><li class=active><a aria-current=page href=../../../docs/learn/lematerial-with-fairchem/>LeMaterial with FAIRChem</a></li></ul></details></li></ul></nav></nav></aside></div></div><button class="btn btn-link nav-link mx-2 order-3 d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasNavMain aria-controls=offcanvasNavMain aria-label="Open main navigation menu"><svg class="icon icon-tabler icon-tabler-menu" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><line x1="4" y1="8" x2="20" y2="8"/><line x1="4" y1="16" x2="20" y2="16"/></svg></button><div class="offcanvas offcanvas-end h-auto" tabindex=-1 id=offcanvasNavMain aria-labelledby=offcanvasNavMainLabel><div class=offcanvas-header><h5 class=offcanvas-title id=offcanvasNavMainLabel>LeMaterial</h5><button type=button class="btn btn-link nav-link p-0 ms-auto" data-bs-dismiss=offcanvas aria-label=Close><svg class="icon icon-tabler icon-tabler-x" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18 6 6 18"/><path d="M6 6l12 12"/></svg></button></div><div class="offcanvas-body d-flex flex-column flex-lg-row justify-content-between"><ul class="navbar-nav flex-grow-1"><li class=nav-item><a class=nav-link href=../../../docs/about/the-mission/>About</a></li><li class=nav-item><a class=nav-link href=../../../docs/reading-group/>Reading Group</a></li></ul><button type=button id=searchToggleDesktop class="btn btn-link nav-link p-2 d-none d-lg-block" aria-label="Search website">
<svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
</button>
<button id=buttonColorMode class="btn btn-link mx-auto nav-link p-0 ms-lg-2 me-lg-1" type=button aria-label="Toggle theme"><svg data-bs-theme-value="dark" class="icon icon-tabler icon-tabler-moon" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 3c.132.0.263.0.393.0a7.5 7.5.0 007.92 12.446A9 9 0 1112 2.992z"/></svg><svg data-bs-theme-value="light" class="icon icon-tabler icon-tabler-sun" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 12m-4 0a4 4 0 108 0 4 4 0 10-8 0m-5 0h1m8-9v1m8 8h1m-9 8v1M5.6 5.6l.7.7m12.1-.7-.7.7m0 11.4.7.7m-12.1-.7-.7.7"/></svg></button><ul id=socialMenu class="nav mx-auto flex-row order-lg-4"><li class=nav-item><a class="nav-link social-link" href=https://huggingface.co/lematerial><svg width="20" height="20" viewBox="0 0 500 463" fill="none"><path d="M496.592 369.699C500.563 381.093 499.61 393.227 494.315 403.778 490.503 411.48 485.05 417.441 478.379 422.769 470.331 429.099 460.324 434.48 448.253 439.65c-14.401 6.12-31.979 11.87-40.027 13.98C387.63 458.958 367.829 462.334 347.762 462.493 319.066 462.756 294.34 456.004 276.762 438.753 267.656 439.861 258.443 440.494 249.178 440.494 240.389 440.494 231.706 439.967 223.076 438.912c-17.631 17.145-42.251 23.844-70.842 23.581C132.168 462.334 112.366 458.958 91.7177 453.63 83.7229 451.52 66.145 445.77 51.7439 439.65 39.6723 434.48 29.6656 429.099 21.6708 422.769 14.9467 417.441 9.49334 411.48 5.68127 403.778.439661 393.227-.566304 381.093 3.45755 369.699-.248631 360.994-1.20165 351.024 1.71035 339.998 3.03399 334.987 5.20476 330.344 7.95792 326.229 7.37552 324.067 6.89901 321.851 6.58134 319.424 4.56941 304.97 9.59923 291.781 19.0765 281.547 23.7357 276.43 28.7655 272.895 34.0071 270.627c-3.865-16.354-5.8769-33.182-5.8769-50.38C28.1302 98.5969 127.085.0 249.178.0c41.933.0 81.165 11.6058 114.627 31.8633C369.84 35.5561 375.77 39.5126 381.436 43.7329 384.242 45.8431 387.048 48.006 389.748 50.2744 392.501 52.49 395.201 54.8112 397.796 57.1851 405.632 64.3069 412.991 71.9562 419.715 80.133 421.992 82.8235 424.163 85.6194 426.28 88.4681 430.569 94.1128 434.54 99.9685 438.193 106.035 443.752 115.109 448.623 124.604 452.859 134.469 455.665 141.064 458.101 147.816 460.271 154.727 463.501 165.067 465.99 175.723 467.684 186.696 468.213 190.336 468.69 194.028 469.06 197.721 469.802 205.107 470.225 212.598 470.225 220.247c0 16.987-2.012 33.657-5.77100000000002 49.747C470.278 272.262 475.784 275.955 480.92 281.547 490.397 291.781 495.427 305.022 493.415 319.477 493.098 321.851 492.621 324.067 492.039 326.229 494.792 330.344 496.963 334.987 498.286 339.998 501.198 351.024 500.245 360.994 496.592 369.699z" fill="#fff"/><path d="M433.839 221.75c0-100.912-82.308-182.7177-183.839-182.7177S66.1613 120.838 66.1613 221.75c0 100.912 82.3077 182.718 183.8387 182.718S433.839 322.662 433.839 221.75zM45 221.75C45 109.222 136.782 18 250 18c113.218.0 205 91.222 205 203.75S363.218 425.5 250 425.5c-113.218.0-205-91.222-205-203.75z" fill="#000"/><path d="M250 405.5c102.173.0 185-82.268 185-183.75C435 120.268 352.173 38 250 38S65 120.268 65 221.75C65 323.232 147.827 405.5 250 405.5z" fill="#fff"/><path d="M202.198 404.174C216.789 383.118 215.755 367.316 195.735 347.627c-20.02-19.684-31.673-48.482-31.673-48.482S159.709 282.419 149.794 283.958C139.88 285.497 132.6 310.492 153.368 325.783c20.767 15.286-4.136 25.673-12.126 11.316C133.252 322.741 111.435 285.831 100.121 278.772 88.8117 271.713 80.8483 275.668 83.5151 290.218c2.6669 14.551 49.9649 49.818 45.3629 57.45C124.276 355.296 108.058 338.7 108.058 338.7s-50.7501-45.445-61.7993-33.603c-11.0491 11.843 8.3823 21.766 36.0741 38.262 27.6972 16.491 29.8442 20.847 25.9152 27.087C104.314 376.685 43.1836 325.971 37.4417 347.47c-5.7367 21.499 62.3874 27.739 58.183 42.581C91.4203 404.899 47.6372 361.958 38.6823 378.689c-8.9602 16.736 61.7827 36.399 62.3557 36.545C123.889 421.067 181.924 433.426 202.198 404.174z" fill="#fff"/><path d="M90.9935 255C82.4744 255 74.8603 258.477 69.551 264.784 66.2675 268.69 62.8367 274.986 62.5578 284.414 58.985 283.394 55.5489 282.824 52.3391 282.824 44.183 282.824 36.8163 285.93 31.6069 291.573 24.9137 298.815 21.9407 307.715 23.2351 316.62 23.8508 320.861 25.2768 324.663 27.4079 328.182 22.9142 331.795 19.6044 336.826 18.0047 342.876 16.7524 347.619 15.4685 357.497 22.1722 367.673 21.746 368.337 21.3461 369.027 20.9725 369.733 16.9418 377.336 16.684 385.927 20.2411 393.928c5.3935 12.126 18.7957 21.68 44.8214 31.935C81.2536 432.242 96.0661 436.321 96.1976 436.357 117.603 441.874 136.962 444.677 153.721 444.677 184.525 444.677 206.578 435.301 219.27 416.811 239.697 387.036 236.776 359.803 210.346 333.552c-14.629-14.526-24.353-35.945-26.379-40.646C179.884 278.986 169.086 263.513 151.138 263.513H151.133C149.622 263.513 148.096 263.633 146.592 263.869 138.73 265.097 131.858 269.595 126.949 276.361 121.65 269.814 116.504 264.606 111.847 261.667 104.827 257.243 97.813 255 90.9935 255zm0 20.917C93.6771 275.917 96.9553 277.051 100.57 279.331 111.794 286.406 133.452 323.403 141.382 337.793 144.039 342.614 148.581 344.654 152.669 344.654 160.783 344.654 167.118 336.638 153.411 326.451c-20.611-15.327-13.381-40.379-3.541-41.922C150.301 284.461 150.727 284.43 151.138 284.43 160.083 284.43 164.03 299.751 164.03 299.751s11.565 28.865 31.435 48.595C215.334 368.08 216.36 383.919 201.879 405.024 192.002 419.415 173.096 421.292 153.721 421.292 133.626 421.292 112.99 417.772 101.445 414.796 100.877 414.65 30.7019 396.255 39.5946 379.48 41.089 376.661 43.5516 375.532 46.6509 375.532c12.5235.0 35.3026 18.522 45.0951 18.522C93.935 394.054 95.5662 392.371 96.1976 390.112 100.555 374.522 32.6646 369.738 38.3633 348.189 39.3683 344.377 42.094 342.829 45.9248 342.834c16.5489.0 53.6773 28.922 61.4602 28.922C107.979 371.756 108.405 371.584 108.637 371.218 112.536 364.964 110.74 359.872 83.257 343.343c-27.4832-16.535-47.1142-25.755-36.143-37.625C48.3768 304.347 50.1659 303.741 52.3391 303.741 69.0248 303.746 108.447 339.398 108.447 339.398s10.64 10.997 17.076 10.997C127.001 350.395 128.259 349.815 129.111 348.382 133.673 340.737 86.7366 305.388 84.0898 290.804 82.2955 280.921 85.3474 275.917 90.9935 275.917z" fill="#000"/><path d="M296.9 404.174C282.31 383.118 283.343 367.316 303.363 347.627c20.02-19.684 31.674-48.482 31.674-48.482S339.39 282.419 349.304 283.958C359.219 285.497 366.498 310.492 345.731 325.783 324.963 341.069 349.866 351.456 357.856 337.099 365.846 322.741 387.663 285.831 398.978 278.772 410.287 271.713 418.25 275.668 415.583 290.218 412.916 304.769 365.618 340.036 370.22 347.668 374.822 355.296 391.041 338.7 391.041 338.7s50.75-45.445 61.799-33.603C463.889 316.94 444.457 326.863 416.766 343.359c-27.698 16.491-29.845 20.847-25.916 27.087C394.784 376.685 455.915 325.971 461.657 347.47 467.393 368.969 399.269 375.209 403.474 390.051 407.678 404.899 451.461 361.958 460.416 378.689 469.376 395.425 398.633 415.088 398.06 415.234 375.209 421.067 317.175 433.426 296.9 404.174z" fill="#fff"/><path d="M408.105 255C416.624 255 424.238 258.477 429.547 264.784 432.831 268.69 436.262 274.986 436.541 284.414 440.113 283.394 443.549 282.824 446.759 282.824 454.915 282.824 462.282 285.93 467.491 291.573 474.185 298.815 477.158 307.715 475.863 316.62 475.248 320.861 473.822 324.663 471.69 328.182 476.184 331.795 479.494 336.826 481.094 342.876 482.346 347.619 483.63 357.497 476.926 367.673 477.352 368.337 477.752 369.027 478.126 369.733 482.157 377.336 482.414 385.927 478.857 393.928 473.464 406.054 460.062 415.608 434.036 425.863 417.845 432.242 403.032 436.321 402.901 436.357 381.495 441.874 362.136 444.677 345.377 444.677 314.573 444.677 292.52 435.301 279.829 416.811 259.402 387.036 262.322 359.803 288.753 333.552c14.628-14.526 24.352-35.945 26.378-40.646C319.214 278.986 330.012 263.513 347.961 263.513H347.966C349.476 263.513 351.002 263.633 352.507 263.869 360.368 265.097 367.24 269.595 372.15 276.361 377.449 269.814 382.595 264.606 387.252 261.667 394.271 257.243 401.285 255 408.105 255zm0 20.917C405.421 275.917 402.143 277.051 398.528 279.331 387.304 286.406 365.646 323.403 357.716 337.793 355.059 342.614 350.518 344.654 346.429 344.654 338.315 344.654 331.98 336.638 345.687 326.451 366.299 311.124 359.069 286.072 349.229 284.529 348.797 284.461 348.371 284.43 347.961 284.43 339.015 284.43 335.069 299.751 335.069 299.751s-11.566 28.865-31.435 48.595C283.764 368.08 282.738 383.919 297.219 405.024 307.096 419.415 326.002 421.292 345.377 421.292 365.472 421.292 386.108 417.772 397.653 414.796 398.221 414.65 468.397 396.255 459.504 379.48 458.009 376.661 455.547 375.532 452.447 375.532c-12.523.0-35.302 18.522-45.095 18.522C405.163 394.054 403.532 392.371 402.901 390.112c-4.358-15.59 63.533-20.374 57.834-41.923C459.73 344.377 457.004 342.829 453.174 342.834c-16.549.0-53.678 28.922-61.46 28.922C391.119 371.756 390.693 371.584 390.461 371.218 386.562 364.964 388.358 359.872 415.841 343.343c27.484-16.535 47.115-25.755 36.143-37.625C450.722 304.347 448.932 303.741 446.759 303.741 430.074 303.746 390.651 339.398 390.651 339.398s-10.64 10.997-17.075 10.997C372.097 350.395 370.84 349.815 369.987 348.382 365.425 340.737 412.362 305.388 415.009 290.804 416.803 280.921 413.751 275.917 408.105 275.917z" fill="#000"/><path d="M319.277 228.901c0-23.665-30.692 12.403-68.64 12.564C212.692 241.306 182 205.238 182 228.901 182 244.591 189.507 270.109 209.669 285.591c4.012-13.804 26.057-24.862 29.208-23.274C243.364 264.578 243.112 270.844 250.637 276.365 258.163 270.844 257.911 264.58 262.398 262.317 265.551 260.729 287.594 271.787 291.605 285.591c20.162-15.482 27.67-41 27.67-56.688L319.277 228.901z" fill="#0e1116"/><path d="M262.4 262.315C257.913 264.576 258.165 270.842 250.639 276.363 243.114 270.842 243.366 264.578 238.879 262.315 235.726 260.727 213.683 271.785 209.672 285.589 219.866 293.417 233.297 298.678 250.627 298.806 250.631 298.806 250.635 298.806 250.641 298.806 250.646 298.806 250.65 298.806 250.656 298.806 267.986 298.68 281.417 293.417 291.611 285.589 287.6 271.785 265.555 260.727 262.404 262.315H262.4z" fill="#ff323d"/><path d="M373 196C382.389 196 390 188.389 390 179S382.389 162 373 162 356 169.611 356 179 363.611 196 373 196z" fill="#000"/><path d="M128 196C137.389 196 145 188.389 145 179S137.389 162 128 162C118.611 162 111 169.611 111 179s7.611 17 17 17z" fill="#000"/><path d="M313.06 171.596C319.796 173.968 322.476 187.779 329.281 184.171c12.886-6.834 17.779-22.794 10.927-35.647C333.356 135.671 317.354 130.792 304.467 137.626s-17.779 22.793-10.927 35.646C296.774 179.339 307.039 169.475 313.06 171.596z" fill="#0e1116"/><path d="M188.554 171.596C181.818 173.968 179.138 187.779 172.334 184.171c-12.887-6.834-17.779-22.794-10.927-35.647C168.259 135.671 184.26 130.792 197.147 137.626s17.779 22.793 10.927 35.646C204.84 179.339 194.575 169.475 188.554 171.596z" fill="#0e1116"/></svg><small class="ms-2 visually-hidden">Hugging Face</small></a></li><li class=nav-item><a class="nav-link social-link" href=https://github.com/lematerial><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg><small class="ms-2 visually-hidden">GitHub</small></a></li></ul></div></div></div></header></div><div class=modal id=searchModal tabindex=-1 aria-labelledby=searchModalLabel aria-hidden=true><div class="modal-dialog modal-dialog-scrollable modal-fullscreen-md-down"><div class=modal-content><div class=modal-header><h1 class="modal-title fs-5 visually-hidden" id=searchModalLabel>Search</h1><button type=button class="btn-close visually-hidden" data-bs-dismiss=modal aria-label=Close></button><div class="search-input flex-grow-1 d-none"><form id=search-form class=search-form action=# method=post accept-charset=UTF-8 role=search><label for=query class=visually-hidden>Search</label><div class=d-flex><input type=search id=query name=query class="search-text form-control form-control-lg" placeholder=Search aria-label=Search maxlength=128 autocomplete=off>
<button type=button class="btn btn-link text-decoration-none px-0 ms-3 d-md-none" data-bs-dismiss=modal aria-label=Close>Cancel</button></div></form></div></div><div class=modal-body><p class="search-loading status message d-none mt-3 text-center">Loading search indexâ€¦</p><p class="search-no-recent message d-none mt-3 text-center">No recent searches</p><p class="search-no-results message d-none mt-3 text-center">No results for "<strong><span class=query-no-results>Query here</span></strong>"</p><div id=searchResults class=search-results></div><template><article class="search-result list-view"><div class="card my-3"><div class=card-body><header><h2 class="h5 title title-submitted mb-0"><a class="stretched-link text-decoration-none text-reset" href=#>Title here</a></h2><div class="submitted d-none"><time class=created-date>Date here</time></div></header><div class=content>Summary here</div></div></div></article></template></div><div class=modal-footer><ul class="list-inline me-auto d-none d-md-block"><li class=list-inline-item><kbd class=me-2><svg width="15" height="15" aria-label="Enter key" role="img"><g fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M12 3.53088v3c0 1-1 2-2 2H4m3 3-3-3 3-3"/></g></svg></kbd><span class=DocSearch-Label>to select</span></li><li class=list-inline-item><kbd class=me-2><svg width="15" height="15" aria-label="Arrow down" role="img"><g fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 3.5v8m3-3-3 3-3-3"/></g></svg></kbd><kbd class=me-2><svg width="15" height="15" aria-label="Arrow up" role="img"><g fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 11.5v-8m3 3-3-3-3 3"/></g></svg></kbd><span class=DocSearch-Label>to navigate</span></li><li class=list-inline-item><kbd class=me-2><svg width="15" height="15" aria-label="Escape key" role="img"><g fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M13.6167 8.936c-.1065.3583-.6883.962-1.4875.962-.7993.0-1.653-.9165-1.653-2.1258v-.5678c0-1.2548.7896-2.1016 1.653-2.1016s1.3601.4778 1.4875 1.0724M9 6c-.1352-.4735-.7506-.9219-1.46-.8972-.7092.0246-1.344.57-1.344 1.2166s.4198.8812 1.3445.9805C8.465 7.3992 8.968 7.9337 9 8.5s-.454 1.398-1.4595 1.398C6.6593 9.898 6 9 5.963 8.4851m-1.4748.5368c-.2635.5941-.8099.876-1.5443.876s-1.7073-.6248-1.7073-2.204v-.4603c0-1.0416.721-2.131 1.7073-2.131.9864.0 1.6425 1.031 1.5443 2.2492h-2.956"/></g></svg></kbd><span class=DocSearch-Label>to close</span></li></ul><p class=d-md-none>Search by <a class=text-decoration-none href=https://github.com/nextapps-de/flexsearch>FlexSearch</a></p></div></div></div></div><div class="wrap container-lg" role=document><div class=content><div class="row flex-xl-nowrap"><div class="col-lg-5 col-xl-4 docs-sidebar d-none d-lg-block"><nav class="section-nav docs-links"><ul class=list-unstyled><li><a href=../../../docs/reading-group/>Reading Group</a></li><li><details open><summary>About</summary><ul class="list-unstyled list-nested"><li><a href=../../../docs/about/the-mission/>The mission</a></li><li><a href=../../../docs/about/datasets/>Datasets</a></li><li><a href=../../../docs/about/citations/>Citations</a></li><li><a href=../../../docs/about/how-to-join/>How to join?</a></li><li><a href=../../../docs/about/code-of-conduct/>Code of Conduct</a></li></ul></details></li><li><details open open><summary>Tutorials</summary><ul class="list-unstyled list-nested"><li class=active><a aria-current=page href=../../../docs/learn/lematerial-with-fairchem/>LeMaterial with FAIRChem</a></li></ul></details></li></ul></nav></div><nav class="docs-toc d-none d-xl-block col-xl-3" aria-label="Secondary navigation"><div class=page-links><h3>On this page</h3><nav id=toc><ul><li><a href=#setup-the-environment>Setup the environment</a></li><li><a href=#load-the-dataset>Load the dataset</a></li><li><a href=#load-a-model>Load a model</a></li><li><a href=#inference-on-a-single-structure>Inference on a single structure</a></li><li><a href=#create-an-lmdb-dataset>Create an LMDB dataset</a></li><li><a href=#run-batched-inference>Run batched inference</a><ul><li></li></ul></li><li><a href=#train--fine-tune-a-model>Train / fine-tune a model</a></li></ul></nav></div></nav><main class="docs-content col-lg-11 col-xl-9"><h1>LeMaterial with FAIRChem</h1><nav class="toc-mobile d-xl-none" aria-label="Quaternary navigation"><details><summary>On this page</summary><div class=page-links><nav id=TableOfContents><ul><li><a href=#setup-the-environment>Setup the environment</a></li><li><a href=#load-the-dataset>Load the dataset</a></li><li><a href=#load-a-model>Load a model</a></li><li><a href=#inference-on-a-single-structure>Inference on a single structure</a></li><li><a href=#create-an-lmdb-dataset>Create an LMDB dataset</a></li><li><a href=#run-batched-inference>Run batched inference</a><ul><li></li></ul></li><li><a href=#train--fine-tune-a-model>Train / fine-tune a model</a></li></ul></nav></div></details></nav><a target=_blank href="https://colab.research.google.com/drive/1y8_CzKM5Rgsiv9JoPmi9mXphi-kf6Lec?usp=sharing"><img src=https://colab.research.google.com/assets/colab-badge.svg alt="Open In Colab"></a><br><br><p>The goal of this tutorial is to show how to use LeMaterial&rsquo;s dataset with Geometric GNNs designed for molecular property prediction and relaxation from the <a href=https://github.com/FAIR-Chem/fairchem>FAIRChem repository</a>.</p><p>For more information on how to use FAIRChem&rsquo;s models, please refer to the <a href=https://github.com/FAIR-Chem/fairchem>FAIRChem repository</a> and their <a href=https://fair-chem.github.io/>documentation</a>.</p><h2 id=setup-the-environment>Setup the environment<a href=#setup-the-environment class=anchor aria-hidden=true>#</a></h2><p>The best way to setup an environment for FAIRChem is to use the provided conda environment file and to create it with the following command:</p><div class=expressive-code><figure class="frame is-terminal not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>wget https://raw.githubusercontent.com/FAIR-Chem/fairchem/main/packages/env.gpu.yml
</span></span><span class=line><span class=cl>conda env create -f env.gpu.yml
</span></span><span class=line><span class=cl>conda activate fair-chem</span></span></code></pre></div></figure></div><p>Or to separately install the <code>torch_geometric</code> dependencies:</p><div class=expressive-code><figure class="frame is-terminal not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>!pip install torch_geometric
</span></span><span class=line><span class=cl>!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu124.html</span></span></code></pre></div></figure></div><p>Then we need to install FAIRChem on the environment:</p><div class=expressive-code><figure class="frame is-terminal not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install fairchem-core</span></span></code></pre></div></figure></div><p>Or manually (currently recommended way):</p><div class=expressive-code><figure class="frame is-terminal not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>git clone https://github.com/FAIR-Chem/fairchem
</span></span><span class=line><span class=cl>pip install -e fairchem/packages/fairchem-core</span></span></code></pre></div></figure></div><p>We also need to install PyTorch dependencies, make sure to pick the correct version of cuda for PyTorch Geometric, along with the right PyTorch version.</p><div class=expressive-code><figure class="frame not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=err>!</span><span class=n>pip</span> <span class=n>install</span> <span class=n>fairchem</span><span class=o>-</span><span class=n>core</span>
</span></span><span class=line><span class=cl><span class=err>!</span><span class=n>pip</span> <span class=n>install</span> <span class=n>torch_geometric</span>
</span></span><span class=line><span class=cl><span class=err>!</span><span class=n>pip</span> <span class=n>install</span> <span class=n>pyg_lib</span> <span class=n>torch_scatter</span> <span class=n>torch_sparse</span> <span class=n>torch_cluster</span> <span class=n>torch_spline_conv</span> <span class=o>-</span><span class=n>f</span> <span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>data</span><span class=o>.</span><span class=n>pyg</span><span class=o>.</span><span class=n>org</span><span class=o>/</span><span class=n>whl</span><span class=o>/</span><span class=n>torch</span><span class=o>-</span><span class=mf>2.5.0</span><span class=o>+</span><span class=n>cu124</span><span class=o>.</span><span class=n>html</span>
</span></span><span class=line><span class=cl><span class=err>!</span><span class=n>pip</span> <span class=n>install</span> <span class=n>datasets</span></span></span></code></pre></div></figure></div><div class=expressive-code><figure class="frame not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>CPU</span> <span class=o>=</span> <span class=kc>False</span> <span class=c1># Run on CPU</span>
</span></span><span class=line><span class=cl><span class=n>BATCH_SIZE</span> <span class=o>=</span> <span class=mi>2</span> <span class=c1># Train and evaluation batch size</span></span></span></code></pre></div></figure></div><h2 id=load-the-dataset>Load the dataset<a href=#load-the-dataset class=anchor aria-hidden=true>#</a></h2><p>We use the dataset available at <a href=https://huggingface.co/LeMaterial>LeMaterial&rsquo;s Hugging Face space</a>.</p><div class=expressive-code><figure class="frame not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>HF_DATASET_PATH</span> <span class=o>=</span> <span class=s2>&#34;LeMaterial/LeMat-Bulk&#34;</span>
</span></span><span class=line><span class=cl><span class=n>SUBSET</span> <span class=o>=</span> <span class=s2>&#34;compatible_pbe&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=n>HF_DATASET_PATH</span><span class=p>,</span> <span class=n>SUBSET</span><span class=p>)[</span><span class=s2>&#34;train&#34;</span><span class=p>]</span></span></span></code></pre></div></figure></div><pre><code>Downloading data:   0%|          | 0/17 [00:00&lt;?, ?files/s]
Generating train split:   0%|          | 0/5335299 [00:00&lt;?, ? examples/s]
Loading dataset shards:   0%|          | 0/17 [00:00&lt;?, ?it/s]
Resolving data files:   0%|          | 0/17 [00:00&lt;?, ?it/s]
</code></pre><h2 id=load-a-model>Load a model<a href=#load-a-model class=anchor aria-hidden=true>#</a></h2><p>We need to start by loading a trained model on which we can run predictions. For example, we can download a checkpoint from EquiformerV2 available <a href=https://huggingface.co/yilunliao/equiformer_v2>here</a>.</p><div class=expressive-code><figure class="frame not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>huggingface_hub</span> <span class=kn>import</span> <span class=n>hf_hub_download</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>fairchem.core</span> <span class=kn>import</span> <span class=n>OCPCalculator</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>HF_REPOID</span> <span class=o>=</span> <span class=s2>&#34;fairchem/OMAT24&#34;</span>
</span></span><span class=line><span class=cl><span class=n>HF_MODEL_PATH</span> <span class=o>=</span> <span class=s2>&#34;eqV2_31M_omat_mp_salex.pt&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>download_model</span><span class=p>(</span><span class=n>hf_repo_id</span><span class=p>,</span> <span class=n>hf_model_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model_path</span> <span class=o>=</span> <span class=n>hf_hub_download</span><span class=p>(</span><span class=n>repo_id</span><span class=o>=</span><span class=n>hf_repo_id</span><span class=p>,</span> <span class=n>filename</span><span class=o>=</span><span class=n>hf_model_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>model_path</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model_path</span> <span class=o>=</span> <span class=n>download_model</span><span class=p>(</span><span class=n>HF_REPOID</span><span class=p>,</span> <span class=n>HF_MODEL_PATH</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>calc</span> <span class=o>=</span> <span class=n>OCPCalculator</span><span class=p>(</span><span class=n>checkpoint_path</span><span class=o>=</span><span class=n>model_path</span><span class=p>,</span> <span class=n>cpu</span><span class=o>=</span><span class=n>CPU</span><span class=p>)</span></span></span></code></pre></div></figure></div><pre><code>0it [00:00, ?it/s]
eqV2_31M_omat_mp_salex.pt:   0%|          | 0.00/126M [00:00&lt;?, ?B/s]
INFO:root:local rank base: 0
INFO:root:amp: true
...
INFO:root:Loading model: hydra
WARNING:root:equiformerV2_energy_head (EquiformerV2EnergyHead) class is deprecated in favor of equiformerV2_scalar_head  (EqV2ScalarHead)
WARNING:root:equiformerV2_force_head (EquiformerV2ForceHead) class is deprecated in favor of equiformerV2_rank1_head  (EqV2Rank1Head)
INFO:root:Loaded HydraModel with 31207434 parameters.
INFO:root:Loading checkpoint in inference-only mode, not loading keys associated with trainer state!
WARNING:root:No seed has been set in modelcheckpoint or OCPCalculator! Results may not be reproducible on re-run
</code></pre><h2 id=inference-on-a-single-structure>Inference on a single structure<a href=#inference-on-a-single-structure class=anchor aria-hidden=true>#</a></h2><p>We first need to convert a row from the dataset of the material that we want to predict the property to an ASE molecule which can be digested by the model.</p><div class=expressive-code><figure class="frame not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ase</span> <span class=kn>import</span> <span class=n>Atoms</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pymatgen.core.structure</span> <span class=kn>import</span> <span class=n>Structure</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>defaultdict</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ase.calculators.singlepoint</span> <span class=kn>import</span> <span class=n>SinglePointCalculator</span> <span class=c1># To add targets</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pymatgen.io.ase</span> <span class=kn>import</span> <span class=n>AseAtomsAdaptor</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>random_sample</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>row</span> <span class=o>=</span> <span class=n>dataset</span><span class=p>[</span><span class=n>random_sample</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_atoms_from_row</span><span class=p>(</span><span class=n>row</span><span class=p>,</span> <span class=n>add_targets</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>add_forces</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>add_stress</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=c1># Convert row to PyMatGen</span>
</span></span><span class=line><span class=cl>      <span class=n>structure</span> <span class=o>=</span> <span class=n>Structure</span><span class=p>(</span>
</span></span><span class=line><span class=cl>          <span class=p>[</span><span class=n>x</span> <span class=k>for</span> <span class=n>y</span> <span class=ow>in</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;lattice_vectors&#34;</span><span class=p>]</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>y</span><span class=p>],</span>
</span></span><span class=line><span class=cl>          <span class=n>species</span><span class=o>=</span><span class=n>row</span><span class=p>[</span><span class=s2>&#34;species_at_sites&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>          <span class=n>coords</span><span class=o>=</span><span class=n>row</span><span class=p>[</span><span class=s2>&#34;cartesian_site_positions&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>          <span class=n>coords_are_cartesian</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>      <span class=n>atoms</span> <span class=o>=</span> <span class=n>AseAtomsAdaptor</span><span class=o>.</span><span class=n>get_atoms</span><span class=p>(</span><span class=n>structure</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>      <span class=c1># Add the forces and energy as targets</span>
</span></span><span class=line><span class=cl>      <span class=k>if</span> <span class=n>add_targets</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>forces</span><span class=p>,</span> <span class=n>stres</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>add_forces</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=s2>&#34;forces&#34;</span><span class=p>])</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>==</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=s2>&#34;cartesian_site_positions&#34;</span><span class=p>])</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=n>forces</span> <span class=o>=</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;forces&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>          <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=c1># OMAT uses the stress tensor as output as well</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>add_stress</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=s2>&#34;stress_tensor&#34;</span><span class=p>])</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>==</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=s2>&#34;cartesian_site_positions&#34;</span><span class=p>])</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=n>stress</span><span class=o>=</span><span class=n>row</span><span class=p>[</span><span class=s2>&#34;stress_tensor&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>          <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=n>atoms</span><span class=o>.</span><span class=n>calc</span> <span class=o>=</span> <span class=n>SinglePointCalculator</span><span class=p>(</span><span class=n>atoms</span><span class=p>,</span> <span class=n>forces</span><span class=o>=</span><span class=n>forces</span><span class=p>,</span> <span class=n>energy</span><span class=o>=</span><span class=n>row</span><span class=p>[</span><span class=s2>&#34;energy&#34;</span><span class=p>],</span> <span class=n>stress</span><span class=o>=</span><span class=n>stress</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>      <span class=k>return</span> <span class=n>atoms</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>atoms</span> <span class=o>=</span> <span class=n>get_atoms_from_row</span><span class=p>(</span><span class=n>row</span><span class=p>)</span></span></span></code></pre></div></figure></div><p>We can now run the inference on the chosen row of the dataset. Since most models inside FAIRChem are designed to predict the energy and the forces of a material at a given structure (S2EF), we can run relaxation (MD) on the structure to get the energy at the relaxed state as well.</p><p>We first show how to predict the energy property of a material without relaxation and then with relaxation.</p><div class=expressive-code><figure class="frame not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ase.filters</span> <span class=kn>import</span> <span class=n>FrechetCellFilter</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ase.optimize</span> <span class=kn>import</span> <span class=n>FIRE</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>relax_atoms</span><span class=p>(</span><span class=n>atoms</span><span class=p>,</span> <span class=n>steps</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>fmax</span><span class=o>=</span><span class=mf>0.05</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>atoms</span><span class=o>.</span><span class=n>calc</span> <span class=o>=</span> <span class=n>calc</span>
</span></span><span class=line><span class=cl>    <span class=n>dyn</span> <span class=o>=</span> <span class=n>FIRE</span><span class=p>(</span><span class=n>FrechetCellFilter</span><span class=p>(</span><span class=n>atoms</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>dyn</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>fmax</span><span class=o>=</span><span class=n>fmax</span><span class=p>,</span> <span class=n>steps</span><span class=o>=</span><span class=n>steps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>atoms</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=s1>&#39;--&#39;</span> <span class=o>*</span> <span class=mi>5</span><span class=si>}</span><span class=s2> No Relaxation </span><span class=si>{</span><span class=s1>&#39;--&#39;</span> <span class=o>*</span> <span class=mi>5</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>atoms</span> <span class=o>=</span> <span class=n>relax_atoms</span><span class=p>(</span><span class=n>atoms</span><span class=p>,</span> <span class=n>steps</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>predicted_energy</span> <span class=o>=</span> <span class=n>atoms</span><span class=o>.</span><span class=n>get_potential_energy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Predicted energy: </span><span class=si>{</span><span class=n>predicted_energy</span><span class=si>}</span><span class=s2> eV&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;DFT energy: </span><span class=si>{</span><span class=n>row</span><span class=p>[</span><span class=s1>&#39;energy&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> eV&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=o>*</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=s1>&#39;--&#39;</span> <span class=o>*</span> <span class=mi>5</span><span class=si>}</span><span class=s2> With Relaxation </span><span class=si>{</span><span class=s1>&#39;--&#39;</span> <span class=o>*</span> <span class=mi>5</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>atoms</span> <span class=o>=</span> <span class=n>get_atoms_from_row</span><span class=p>(</span><span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>atoms</span> <span class=o>=</span> <span class=n>relax_atoms</span><span class=p>(</span><span class=n>atoms</span><span class=p>,</span> <span class=n>steps</span><span class=o>=</span><span class=mi>200</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>predicted_energy</span> <span class=o>=</span> <span class=n>atoms</span><span class=o>.</span><span class=n>get_potential_energy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Predicted energy: </span><span class=si>{</span><span class=n>predicted_energy</span><span class=si>}</span><span class=s2> eV&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;DFT energy: </span><span class=si>{</span><span class=n>row</span><span class=p>[</span><span class=s1>&#39;energy&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> eV&#34;</span><span class=p>)</span></span></span></code></pre></div></figure></div><pre><code>---------- No Relaxation ----------
  Step     Time          Energy          fmax
FIRE:    0 14:54:04       -5.517979        0.267703
Predicted energy: -5.517978668212891 eV
DFT energy: -5.57597026 eV
---------- With Relaxation ----------
      Step     Time          Energy          fmax
FIRE:    0 14:54:04       -5.517979        0.267703
FIRE:    1 14:54:05       -5.520627        0.276172
FIRE:    2 14:54:05       -5.524797        0.263472
FIRE:    3 14:54:06       -5.527802        0.213701
FIRE:    4 14:54:06       -5.529005        0.166641
FIRE:    5 14:54:07       -5.529183        0.136835
FIRE:    6 14:54:07       -5.529638        0.124812
FIRE:    7 14:54:07       -5.531461        0.123644
FIRE:    8 14:54:08       -5.532405        0.125816
FIRE:    9 14:54:08       -5.534833        0.127752
FIRE:   10 14:54:08       -5.536007        0.130083
FIRE:   11 14:54:09       -5.535960        0.128654
FIRE:   12 14:54:09       -5.536138        0.120737
FIRE:   13 14:54:09       -5.533516        0.108630
FIRE:   14 14:54:10       -5.530128        0.100276
FIRE:   15 14:54:10       -5.528875        0.096984
FIRE:   16 14:54:10       -5.529051        0.104039
FIRE:   17 14:54:11       -5.570351        0.031070
Predicted energy: -5.5703511238098145 eV
DFT energy: -5.57597026 eV
</code></pre><h2 id=create-an-lmdb-dataset>Create an LMDB dataset<a href=#create-an-lmdb-dataset class=anchor aria-hidden=true>#</a></h2><p>In order to run batched inference, we need to create a database compatible with FAIRChem&rsquo;s dataloader. The recommended way to do is to currently create an ASE LMDB database and pass it to FAIRChem&rsquo;s config.</p><div class=expressive-code><figure class="frame not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>tqdm</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ase</span> <span class=kn>import</span> <span class=n>Atoms</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>fairchem.core.datasets.lmdb_database</span> <span class=kn>import</span> <span class=n>LMDBDatabase</span></span></span></code></pre></div></figure></div><p>We will create an LMDB database based on LeMaterial&rsquo;s entire dataset. Note that you can also use a subset of the dataset if you want to by filtering relevant structures for example. This could allow to fine-tune on selected materials, or test the model on a specific subset of materials.</p><p>We discuss about training and fine-tuning in the last section of this notebook.</p><div class=expressive-code><figure class="frame not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># REF: https://github.com/FAIR-Chem/fairchem/issues/787</span>
</span></span><span class=line><span class=cl><span class=n>output_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=s2>&#34;leMat.aselmdb&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>select_range</span> <span class=o>=</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl><span class=n>small_dataset</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=n>select_range</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>tqdm</span><span class=o>.</span><span class=n>tqdm</span><span class=p>(</span><span class=n>small_dataset</span><span class=p>,</span> <span class=n>total</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>small_dataset</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>LMDBDatabase</span><span class=p>(</span><span class=n>output_path</span><span class=p>)</span> <span class=k>as</span> <span class=n>db</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>atoms</span> <span class=o>=</span> <span class=n>get_atoms_from_row</span><span class=p>(</span><span class=n>row</span><span class=p>,</span> <span class=n>add_targets</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span> <span class=c1># not needed for inference</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>db</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>atoms</span><span class=p>,</span> <span class=n>data</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;id&#34;</span><span class=p>:</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;immutable_id&#34;</span><span class=p>]})</span></span></span></code></pre></div></figure></div><pre><code>100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00&lt;00:00, 118.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01&lt;00:00, 86.01it/s]
</code></pre><h2 id=run-batched-inference>Run batched inference<a href=#run-batched-inference class=anchor aria-hidden=true>#</a></h2><h4 id=load-the-created-lmdb-dataset-in-model>Load the created LMDB dataset in model<a href=#load-the-created-lmdb-dataset-in-model class=anchor aria-hidden=true>#</a></h4><p>The model object loaded from the checkpoint contains all the necessary information on the config file, including the paths to the train, test and validation splits. We can use this information to load our newly created LeMaterial&rsquo;s LMDB dataset to the model.</p><div class=expressive-code><figure class="frame not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>fairchem.core.common.tutorial_utils</span> <span class=kn>import</span> <span class=n>generate_yml_config</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>yaml</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>yml_path</span> <span class=o>=</span> <span class=n>generate_yml_config</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model_path</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;/tmp/config.yml&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>delete</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;logger&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;task&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;model_attributes&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;dataset&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;slurm&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;optim.load_balancing&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=c1># Load balancing works only if a metadata.npz file is generated using the make_lmdb script (see: https://github.com/FAIR-Chem/fairchem/issues/876)</span>
</span></span><span class=line><span class=cl>    <span class=n>update</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;amp&#34;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;gpus&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;task.prediction_dtype&#34;</span><span class=p>:</span> <span class=s2>&#34;float32&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;logger&#34;</span><span class=p>:</span> <span class=s2>&#34;tensorboard&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=c1># Test data - prediction only so no regression</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;test_dataset.src&#34;</span><span class=p>:</span> <span class=s2>&#34;leMat.aselmdb&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;test_dataset.format&#34;</span><span class=p>:</span> <span class=s2>&#34;ase_db&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;test_dataset.2g_args.r_energy&#34;</span><span class=p>:</span> <span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;test_dataset.a2g_args.r_forces&#34;</span><span class=p>:</span> <span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;optim.eval_batch_size&#34;</span><span class=p>:</span> <span class=n>BATCH_SIZE</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div></figure></div><pre><code>INFO:root:Loading model: hydra
WARNING:root:equiformerV2_energy_head (EquiformerV2EnergyHead) class is deprecated in favor of equiformerV2_scalar_head  (EqV2ScalarHead)
WARNING:root:equiformerV2_force_head (EquiformerV2ForceHead) class is deprecated in favor of equiformerV2_rank1_head  (EqV2Rank1Head)
INFO:root:Loaded HydraModel with 31207434 parameters.
INFO:root:Loading checkpoint in inference-only mode, not loading keys associated with trainer state!
WARNING:root:No seed has been set in modelcheckpoint or OCPCalculator! Results may not be reproducible on re-run
/usr/local/lib/python3.10/dist-packages/fairchem/core/common/relaxation/ase_utils.py:190: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=torch.device(&quot;cpu&quot;))
INFO:root:amp: true
...
INFO:root:Loading model: hydra
WARNING:root:equiformerV2_energy_head (EquiformerV2EnergyHead) class is deprecated in favor of equiformerV2_scalar_head  (EqV2ScalarHead)
WARNING:root:equiformerV2_force_head (EquiformerV2ForceHead) class is deprecated in favor of equiformerV2_rank1_head  (EqV2Rank1Head)
INFO:root:Loaded HydraModel with 31207434 parameters.
INFO:root:Loading checkpoint in inference-only mode, not loading keys associated with trainer state!
WARNING:root:No seed has been set in modelcheckpoint or OCPCalculator! Results may not be reproducible on re-run
</code></pre><h4 id=run-batched-inference-1>Run batched inference<a href=#run-batched-inference-1 class=anchor aria-hidden=true>#</a></h4><div class=expressive-code><figure class="frame not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>fairchem.core.common.tutorial_utils</span> <span class=kn>import</span> <span class=n>fairchem_main</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Recommended way to run inference</span>
</span></span><span class=line><span class=cl><span class=n>yml_path</span> <span class=o>=</span> <span class=n>generate_yml_config</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model_path</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;/tmp/config.yml&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>delete</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;logger&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;task&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;model_attributes&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;slurm&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;optim.load_balancing&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=c1># Load balancing works only if a metadata.npz file is generated using the make_lmdb script (see: https://github.com/FAIR-Chem/fairchem/issues/876)</span>
</span></span><span class=line><span class=cl>    <span class=n>update</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;amp&#34;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;gpus&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;task.prediction_dtype&#34;</span><span class=p>:</span> <span class=s2>&#34;float32&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;logger&#34;</span><span class=p>:</span> <span class=s2>&#34;tensorboard&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=c1># Compatibility issues between current fairchem version and OMAT24 model? (not needed for inference)</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;loss_functionsn&#34;</span><span class=p>:</span> <span class=s2>&#34;mae&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=c1># Test data - prediction only so no regression</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;test_dataset.src&#34;</span><span class=p>:</span> <span class=s2>&#34;leMat.aselmdb&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;test_dataset.format&#34;</span><span class=p>:</span> <span class=s2>&#34;ase_db&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;test_dataset.2g_args.r_energy&#34;</span><span class=p>:</span> <span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;test_dataset.a2g_args.r_forces&#34;</span><span class=p>:</span> <span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;optim.eval_batch_size&#34;</span><span class=p>:</span> <span class=n>BATCH_SIZE</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>locale</span>
</span></span><span class=line><span class=cl><span class=n>locale</span><span class=o>.</span><span class=n>getpreferredencoding</span> <span class=o>=</span> <span class=k>lambda</span><span class=p>:</span> <span class=s2>&#34;UTF-8&#34;</span> <span class=c1># For running the main script</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=err>!</span><span class=n>python</span> <span class=p>{</span><span class=n>fairchem_main</span><span class=p>()}</span> <span class=o>--</span><span class=n>mode</span> <span class=n>predict</span> <span class=o>--</span><span class=n>config</span><span class=o>-</span><span class=n>yml</span> <span class=p>{</span><span class=n>yml_path</span><span class=p>}</span> <span class=o>--</span><span class=n>checkpoint</span> <span class=p>{</span><span class=n>model_path</span><span class=p>}</span> <span class=p>{</span><span class=s1>&#39;--cpu&#39;</span> <span class=k>if</span> <span class=n>CPU</span> <span class=k>else</span> <span class=s1>&#39;&#39;</span><span class=p>}</span></span></span></code></pre></div></figure></div><div class=expressive-code><figure class="frame not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># If you want to have control over the trainer object (and for example add hooks on the modules)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>yml_path</span> <span class=o>=</span> <span class=n>generate_yml_config</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model_path</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;/tmp/config.yml&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>delete</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;logger&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;task&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;dataset&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;model_attributes&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;slurm&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;optim.load_balancing&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=c1># Load balancing works only if a metadata.npz file is generated using the make_lmdb script (see: https://github.com/FAIR-Chem/fairchem/issues/876)</span>
</span></span><span class=line><span class=cl>    <span class=n>update</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;amp&#34;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;gpus&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;task.prediction_dtype&#34;</span><span class=p>:</span> <span class=s2>&#34;float32&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;logger&#34;</span><span class=p>:</span> <span class=s2>&#34;tensorboard&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=c1># Test data - prediction only so no regression</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;test_dataset.src&#34;</span><span class=p>:</span> <span class=s2>&#34;leMat.aselmdb&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;test_dataset.format&#34;</span><span class=p>:</span> <span class=s2>&#34;ase_db&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;test_dataset.2g_args.r_energy&#34;</span><span class=p>:</span> <span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;test_dataset.a2g_args.r_forces&#34;</span><span class=p>:</span> <span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;optim.eval_batch_size&#34;</span><span class=p>:</span> <span class=n>BATCH_SIZE</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>config</span> <span class=o>=</span> <span class=n>yaml</span><span class=o>.</span><span class=n>safe_load</span><span class=p>(</span><span class=nb>open</span><span class=p>(</span><span class=n>yml_path</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>config</span><span class=p>[</span><span class=s2>&#34;dataset&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl><span class=n>config</span><span class=p>[</span><span class=s2>&#34;val_dataset&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>config</span><span class=p>[</span><span class=s2>&#34;optim&#34;</span><span class=p>][</span><span class=s2>&#34;scheduler_params&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;lambda_type&#39;</span><span class=p>:</span> <span class=s1>&#39;cosine&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s1>&#39;warmup_factor&#39;</span><span class=p>:</span> <span class=mf>0.2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s1>&#39;warmup_epochs&#39;</span><span class=p>:</span> <span class=mi>463</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s1>&#39;lr_min_factor&#39;</span><span class=p>:</span> <span class=mf>0.01</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>calc</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
</span></span><span class=line><span class=cl><span class=n>calc</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>load_datasets</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>calc</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>is_debug</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=n>calc</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>calc</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>test_loader</span><span class=p>,</span> <span class=n>calc</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>test_sampler</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div></figure></div><pre><code>INFO:root:Loading model: hydra
WARNING:root:equiformerV2_energy_head (EquiformerV2EnergyHead) class is deprecated in favor of equiformerV2_scalar_head  (EqV2ScalarHead)
WARNING:root:equiformerV2_force_head (EquiformerV2ForceHead) class is deprecated in favor of equiformerV2_rank1_head  (EqV2Rank1Head)
INFO:root:Loaded HydraModel with 31207434 parameters.
INFO:root:Loading checkpoint in inference-only mode, not loading keys associated with trainer state!
WARNING:root:No seed has been set in modelcheckpoint or OCPCalculator! Results may not be reproducible on re-run
WARNING:root:Could not find dataset metadata.npz files in '[PosixPath('leMat.aselmdb')]'
WARNING:root:Disabled BalancedBatchSampler because num_replicas=1.
WARNING:root:Failed to get data sizes, falling back to uniform partitioning. BalancedBatchSampler requires a dataset that has a metadata attributed with number of atoms.
INFO:root:rank: 0: Sampler created...
INFO:root:Created BalancedBatchSampler with sampler=&lt;fairchem.core.common.data_parallel.StatefulDistributedSampler object at 0x794e8f76eec0&gt;, batch_size=2, drop_last=False
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
INFO:root:Predicting on test.
device 0:   0%|          | 0/50 [00:00&lt;?, ?it/s]/usr/local/lib/python3.10/dist-packages/fairchem/core/trainers/ocp_trainer.py:471: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=self.scaler is not None):
device 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:13&lt;00:00,  3.78it/s]

INFO:root:Loading model: hydra
WARNING:root:equiformerV2_energy_head (EquiformerV2EnergyHead) class is deprecated in favor of equiformerV2_scalar_head  (EqV2ScalarHead)
WARNING:root:equiformerV2_force_head (EquiformerV2ForceHead) class is deprecated in favor of equiformerV2_rank1_head  (EqV2Rank1Head)
INFO:root:Loaded HydraModel with 31207434 parameters.
INFO:root:Loading checkpoint in inference-only mode, not loading keys associated with trainer state!
WARNING:root:No seed has been set in modelcheckpoint or OCPCalculator! Results may not be reproducible on re-run
WARNING:root:Could not find dataset metadata.npz files in '[PosixPath('leMat.aselmdb')]'
WARNING:root:Disabled BalancedBatchSampler because num_replicas=1.
WARNING:root:Failed to get data sizes, falling back to uniform partitioning. BalancedBatchSampler requires a dataset that has a metadata attributed with number of atoms.
INFO:root:rank: 0: Sampler created...
INFO:root:Created BalancedBatchSampler with sampler=&lt;fairchem.core.common.data_parallel.StatefulDistributedSampler object at 0x794e8f6f2260&gt;, batch_size=2, drop_last=False
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
INFO:root:Predicting on test.
device 0:   0%|          | 0/100 [00:00&lt;?, ?it/s]/usr/local/lib/python3.10/dist-packages/fairchem/core/trainers/ocp_trainer.py:471: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=self.scaler is not None):
device 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:22&lt;00:00,  4.35it/s]

defaultdict(list,
            {'energy': [array([-92.6361], dtype=float32),
              array([-67.37538], dtype=float32),
              array([-46.047863], dtype=float32),
              array([-14.097839], dtype=float32),
              ...
</code></pre><h2 id=train--fine-tune-a-model>Train / fine-tune a model<a href=#train--fine-tune-a-model class=anchor aria-hidden=true>#</a></h2><p>In order to train models with our dataset, we need to create the train and validation splits as well. This will require specifying the targets in the LMDB and letting the model correctly pick them up.</p><p>Since LeMaterial&rsquo;s database is composed of atomic forces and energies at a given structure (no trajectories for now), we want to use the energy and the forces as targets of an S2EF model. Note that EquiformerV2 trained on OMAT is an S2EFS (stress) model, so stress needs to be added to targets.</p><p>In order to train models with our dataset, we need to create the train and validation splits as well. This will require specifying the targets in the LMDB and letting the model correctly pick them up.</p><p>We provide an example of how it is possible to generate a few LMDB datasets and then plug use them for training a model. Notice that we need the targets in here which are directly read by the <code>Atoms2Graph</code> class internally.</p><div class=expressive-code><figure class="frame not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>ADD_STRESS</span> <span class=o>=</span> <span class=kc>True</span> <span class=c1># Need for omat24 models! (S2E&#39;S)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>splits</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;train&#34;</span><span class=p>:</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1000</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;val&#34;</span><span class=p>:</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1000</span><span class=p>,</span> <span class=mi>2000</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;test&#34;</span><span class=p>:</span> <span class=nb>range</span><span class=p>(</span><span class=mi>2000</span><span class=p>,</span> <span class=mi>3000</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>split</span> <span class=ow>in</span> <span class=n>splits</span><span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=n>small_dataset</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=n>splits</span><span class=p>[</span><span class=n>split</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>tqdm</span><span class=o>.</span><span class=n>tqdm</span><span class=p>(</span><span class=n>small_dataset</span><span class=p>,</span> <span class=n>total</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>small_dataset</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>      <span class=k>with</span> <span class=n>LMDBDatabase</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;leMat_</span><span class=si>{</span><span class=n>split</span><span class=si>}</span><span class=s2>.aselmdb&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>db</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=n>atoms</span> <span class=o>=</span> <span class=n>get_atoms_from_row</span><span class=p>(</span><span class=n>row</span><span class=p>,</span> <span class=n>add_targets</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>add_forces</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>add_stress</span><span class=o>=</span><span class=n>ADD_STRESS</span><span class=p>)</span> <span class=c1># Reject if there are no forces in the dataset</span>
</span></span><span class=line><span class=cl>          <span class=k>if</span> <span class=n>atoms</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>             <span class=k>continue</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>          <span class=n>db</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>atoms</span><span class=p>,</span> <span class=n>data</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;id&#34;</span><span class=p>:</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;immutable_id&#34;</span><span class=p>]})</span></span></span></code></pre></div></figure></div><pre><code>100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:02&lt;00:00, 345.02it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:02&lt;00:00, 384.47it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01&lt;00:00, 604.11it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:03&lt;00:00, 266.96it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:02&lt;00:00, 372.12it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01&lt;00:00, 580.56it/s]
</code></pre><p>Since creating LMDB files takes significantly more time as the size increases, we recommend separating the datasets into smaller chunks of .aselmdb files that are in the same directory and then redirect the config to this directory instead of the aselmdb file. The data loaders are then able to correctly concatenate the files as needed.</p><p>Many model implementations exist in fairchem. This is an example of a few and how we use them. More of these can be found <a href=https://github.com/FAIR-Chem/fairchem/tree/main/configs>here</a>.</p><div class=expressive-code><figure class="frame not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>example_configs</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;eqv2_omat_S&#34;</span><span class=p>:</span> <span class=s2>&#34;configs/omat24/all/eqV2_31M.yml&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;eqv2_omat_S&#34;</span><span class=p>:</span> <span class=s2>&#34;configs/omat24/all/eqV2_31M.yml&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;eqv2_s2ef_L&#34;</span><span class=p>:</span> <span class=s2>&#34;configs/s2ef/all/equiformer_v2/equiformer_v2_N@20_L@6_M@3_153M.yml&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;eqv2_s2ef_S&#34;</span><span class=p>:</span> <span class=s2>&#34;configs/s2ef/all/equiformer_v2/equiformer_v2_N@8_L@4_M@2_31M.yml&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;dpp&#34;</span><span class=p>:</span> <span class=s2>&#34;configs/s2ef/all/dimenet_plus_plus/dpp.yml&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>CHOSEN_MODEL</span> <span class=o>=</span> <span class=s2>&#34;dpp&#34;</span></span></span></code></pre></div></figure></div><p>We need to apply a little bit of processing on the yaml config files to be able to read them with the main script of FAIRChem.</p><ul><li>Apply the datasets</li><li>Change some config parameters (this can be adjusted depending on what you want to put in the model)</li></ul><p>More information on how to tweak this config file can be found in FAIRChem&rsquo;s documentation as well. Note that you can also modify some config arguments with the cli parameters directly.</p><div class=expressive-code><figure class="frame not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>fairchem.core.common.tutorial_utils</span> <span class=kn>import</span> <span class=n>fairchem_main</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>yaml</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=err>!</span><span class=n>git</span> <span class=n>clone</span> <span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>github</span><span class=o>.</span><span class=n>com</span><span class=o>/</span><span class=n>FAIR</span><span class=o>-</span><span class=n>Chem</span><span class=o>/</span><span class=n>fairchem</span><span class=o>.</span><span class=n>git</span> <span class=c1># to download configs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>config_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=s2>&#34;fairchem&#34;</span><span class=p>)</span> <span class=o>/</span> <span class=n>example_configs</span><span class=p>[</span><span class=n>CHOSEN_MODEL</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>yaml_obj</span> <span class=o>=</span> <span class=n>yaml</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=nb>open</span><span class=p>(</span><span class=n>config_path</span><span class=p>,</span> <span class=s2>&#34;r&#34;</span><span class=p>),</span> <span class=n>Loader</span><span class=o>=</span><span class=n>yaml</span><span class=o>.</span><span class=n>FullLoader</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Change these parameters according to need</span>
</span></span><span class=line><span class=cl><span class=n>include_dict</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;trainer&#39;</span><span class=p>:</span> <span class=s1>&#39;ocp&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;logger&#39;</span><span class=p>:</span> <span class=s1>&#39;tensorboard&#39;</span><span class=p>,</span> <span class=c1># or wandb</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;outputs&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;energy&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;shape&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;level&#39;</span><span class=p>:</span> <span class=s1>&#39;system&#39;</span><span class=p>},</span> <span class=s1>&#39;forces&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;irrep_dim&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;level&#39;</span><span class=p>:</span> <span class=s1>&#39;atom&#39;</span><span class=p>,</span> <span class=s1>&#39;train_on_free_atoms&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span> <span class=s1>&#39;eval_on_free_atoms&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>}},</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;loss_functions&#39;</span><span class=p>:</span> <span class=p>[{</span><span class=s1>&#39;energy&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;fn&#39;</span><span class=p>:</span> <span class=s1>&#39;mae&#39;</span><span class=p>,</span> <span class=s1>&#39;coefficient&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>}},</span> <span class=p>{</span><span class=s1>&#39;forces&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;fn&#39;</span><span class=p>:</span> <span class=s1>&#39;l2mae&#39;</span><span class=p>,</span> <span class=s1>&#39;coefficient&#39;</span><span class=p>:</span> <span class=mi>100</span><span class=p>}}],</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;evaluation_metrics&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;metrics&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;energy&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;mae&#39;</span><span class=p>],</span> <span class=s1>&#39;forces&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;mae&#39;</span><span class=p>,</span> <span class=s1>&#39;cosine_similarity&#39;</span><span class=p>,</span> <span class=s1>&#39;magnitude_error&#39;</span><span class=p>],</span> <span class=s1>&#39;misc&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;energy_forces_within_threshold&#39;</span><span class=p>]},</span> <span class=s1>&#39;primary_metric&#39;</span><span class=p>:</span> <span class=s1>&#39;forces_mae&#39;</span><span class=p>}</span>
</span></span><span class=line><span class=cl>                <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>yaml_obj</span><span class=p>[</span><span class=s2>&#34;dataset&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;train&#34;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;src&#34;</span><span class=p>:</span> <span class=s2>&#34;leMat_train.aselmdb&#34;</span><span class=p>,</span> <span class=s2>&#34;format&#34;</span><span class=p>:</span> <span class=s2>&#34;ase_db&#34;</span><span class=p>,</span> <span class=s2>&#34;a2g_args&#34;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;r_energy&#34;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span> <span class=s2>&#34;r_forces&#34;</span><span class=p>:</span> <span class=kc>True</span><span class=p>}},</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;val&#34;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;src&#34;</span><span class=p>:</span> <span class=s2>&#34;leMat_val.aselmdb&#34;</span><span class=p>,</span> <span class=s2>&#34;format&#34;</span><span class=p>:</span> <span class=s2>&#34;ase_db&#34;</span><span class=p>,</span> <span class=s2>&#34;a2g_args&#34;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;r_energy&#34;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span> <span class=s2>&#34;r_forces&#34;</span><span class=p>:</span> <span class=kc>True</span><span class=p>}},</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;test&#34;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;src&#34;</span><span class=p>:</span> <span class=s2>&#34;leMat_test.aselmdb&#34;</span><span class=p>,</span> <span class=s2>&#34;format&#34;</span><span class=p>:</span> <span class=s2>&#34;ase_db&#34;</span><span class=p>,</span> <span class=s2>&#34;a2g_args&#34;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;r_energy&#34;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span> <span class=s2>&#34;r_forces&#34;</span><span class=p>:</span> <span class=kc>True</span><span class=p>}},</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=s2>&#34;includes&#34;</span> <span class=ow>in</span> <span class=n>yaml_obj</span><span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=k>del</span> <span class=n>yaml_obj</span><span class=p>[</span><span class=s2>&#34;includes&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>yaml_obj</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>include_dict</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>yaml_obj</span><span class=p>[</span><span class=s2>&#34;model&#34;</span><span class=p>][</span><span class=s2>&#34;otf_graph&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># For equiformer models: set the trainer to the equiformerv2_forces one</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=s2>&#34;eqv2&#34;</span> <span class=ow>in</span> <span class=n>CHOSEN_MODEL</span><span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=n>yaml_obj</span><span class=p>[</span><span class=s2>&#34;trainer&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;equiformerv2_forces&#34;</span>
</span></span><span class=line><span class=cl>  <span class=n>yaml_obj</span><span class=p>[</span><span class=s2>&#34;optim&#34;</span><span class=p>][</span><span class=s2>&#34;scheduler_params&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;lambda_type&#39;</span><span class=p>:</span> <span class=s1>&#39;cosine&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s1>&#39;warmup_factor&#39;</span><span class=p>:</span> <span class=mf>0.2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s1>&#39;warmup_epochs&#39;</span><span class=p>:</span> <span class=mi>463</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s1>&#39;lr_min_factor&#39;</span><span class=p>:</span> <span class=mf>0.01</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># No metadata.npz file, disabling load_balancing</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=s2>&#34;load_balancing&#34;</span> <span class=ow>in</span> <span class=n>yaml_obj</span><span class=p>[</span><span class=s2>&#34;optim&#34;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>  <span class=k>del</span> <span class=n>yaml_obj</span><span class=p>[</span><span class=s2>&#34;optim&#34;</span><span class=p>][</span><span class=s2>&#34;load_balancing&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>new_yaml_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;/tmp/</span><span class=si>{</span><span class=n>CHOSEN_MODEL</span><span class=si>}</span><span class=s2>_leMat.yml&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>new_yaml_path</span><span class=p>,</span> <span class=s2>&#34;w&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>yaml</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>yaml_obj</span><span class=p>,</span> <span class=n>f</span><span class=p>)</span></span></span></code></pre></div></figure></div><pre><code>fatal: destination path 'fairchem' already exists and is not an empty directory.
</code></pre><div class=expressive-code><figure class="frame not-content"><figcaption class=header><span class=title></span></figcaption><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Unclear whether it is possible to access this main.py script from the pip package</span>
</span></span><span class=line><span class=cl><span class=err>!</span><span class=n>python</span> <span class=n>fairchem</span><span class=o>/</span><span class=n>main</span><span class=o>.</span><span class=n>py</span> <span class=o>--</span><span class=n>mode</span> <span class=n>train</span> <span class=o>--</span><span class=n>config</span><span class=o>-</span><span class=n>yml</span> <span class=o>/</span><span class=n>tmp</span><span class=o>/</span><span class=p>{</span><span class=n>CHOSEN_MODEL</span><span class=p>}</span><span class=n>_leMat</span><span class=o>.</span><span class=n>yml</span> <span class=p>{</span><span class=s2>&#34;--cpu&#34;</span> <span class=k>if</span> <span class=n>CPU</span> <span class=k>else</span> <span class=s2>&#34;&#34;</span><span class=p>}</span></span></span></code></pre></div></figure></div><pre><code>2024-12-12 14:38:02 (INFO): Running in local mode without elastic launch (single gpu only)
2024-12-12 14:38:02 (INFO): Setting env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
[W1212 14:38:02.705129468 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
2024-12-12 14:38:02 (INFO): Project root: /usr/local/lib/python3.10/dist-packages/fairchem
2024-12-12 14:38:02.967649: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-12-12 14:38:02.986891: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-12-12 14:38:02.992752: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-12-12 14:38:04.287556: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-12-12 14:38:05 (INFO): NumExpr defaulting to 2 threads.
/usr/local/lib/python3.10/dist-packages/fairchem/core/models/scn/spherical_harmonics.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  _Jd = torch.load(os.path.join(os.path.dirname(__file__), &quot;Jd.pt&quot;))
/usr/local/lib/python3.10/dist-packages/fairchem/core/models/equiformer_v2/wigner.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  _Jd = torch.load(os.path.join(os.path.dirname(__file__), &quot;Jd.pt&quot;))
/usr/local/lib/python3.10/dist-packages/fairchem/core/models/equiformer_v2/layer_norm.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/usr/local/lib/python3.10/dist-packages/fairchem/core/models/equiformer_v2/layer_norm.py:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/usr/local/lib/python3.10/dist-packages/fairchem/core/models/equiformer_v2/layer_norm.py:263: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/usr/local/lib/python3.10/dist-packages/fairchem/core/models/equiformer_v2/layer_norm.py:357: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/usr/local/lib/python3.10/dist-packages/fairchem/core/models/escn/so3.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  _Jd = torch.load(os.path.join(os.path.dirname(__file__), &quot;Jd.pt&quot;))
2024-12-12 14:38:07 (INFO): local rank base: 0
2024-12-12 14:38:07 (INFO): amp: false
...
2024-12-12 14:38:07 (INFO): Loading model: dimenetplusplus
2024-12-12 14:38:25 (INFO): Loaded DimeNetPlusPlusWrap with 1810182 parameters.
2024-12-12 14:38:25 (WARNING): log_summary for Tensorboard not supported
2024-12-12 14:38:25 (INFO): Loading dataset: ase_db
2024-12-12 14:38:25 (WARNING): Could not find dataset metadata.npz files in '[PosixPath('leMat_train.aselmdb')]'
2024-12-12 14:38:25 (WARNING): Disabled BalancedBatchSampler because num_replicas=1.
2024-12-12 14:38:25 (WARNING): Failed to get data sizes, falling back to uniform partitioning. BalancedBatchSampler requires a dataset that has a metadata attributed with number of atoms.
2024-12-12 14:38:25 (INFO): rank: 0: Sampler created...
2024-12-12 14:38:25 (INFO): Created BalancedBatchSampler with sampler=&lt;fairchem.core.common.data_parallel.StatefulDistributedSampler object at 0x7ed8d5dc2a70&gt;, batch_size=8, drop_last=False
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
2024-12-12 14:38:25 (WARNING): Could not find dataset metadata.npz files in '[PosixPath('leMat_val.aselmdb')]'
2024-12-12 14:38:25 (WARNING): Disabled BalancedBatchSampler because num_replicas=1.
2024-12-12 14:38:25 (WARNING): Failed to get data sizes, falling back to uniform partitioning. BalancedBatchSampler requires a dataset that has a metadata attributed with number of atoms.
2024-12-12 14:38:25 (INFO): rank: 0: Sampler created...
2024-12-12 14:38:25 (INFO): Created BalancedBatchSampler with sampler=&lt;fairchem.core.common.data_parallel.StatefulDistributedSampler object at 0x7ed8d5b5b490&gt;, batch_size=8, drop_last=False
2024-12-12 14:38:25 (WARNING): Could not find dataset metadata.npz files in '[PosixPath('leMat_test.aselmdb')]'
2024-12-12 14:38:25 (WARNING): Disabled BalancedBatchSampler because num_replicas=1.
2024-12-12 14:38:25 (WARNING): Failed to get data sizes, falling back to uniform partitioning. BalancedBatchSampler requires a dataset that has a metadata attributed with number of atoms.
2024-12-12 14:38:25 (INFO): rank: 0: Sampler created...
2024-12-12 14:38:25 (INFO): Created BalancedBatchSampler with sampler=&lt;fairchem.core.common.data_parallel.StatefulDistributedSampler object at 0x7ed8d5e109d0&gt;, batch_size=8, drop_last=False
/usr/local/lib/python3.10/dist-packages/fairchem/core/trainers/ocp_trainer.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=self.scaler is not None):
/usr/local/lib/python3.10/dist-packages/fairchem/core/models/dimenet_plus_plus.py:445: UserWarning: Using torch.cross without specifying the dim arg is deprecated.
Please either pass the dim explicitly or simply use torch.linalg.cross.
The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at ../aten/src/ATen/native/Cross.cpp:62.)
  b = torch.cross(pos_ji, pos_kj).norm(dim=-1)
/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1, 192], strides() = [1, 1]
bucket_view.sizes() = [1, 192], strides() = [192, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2024-12-12 14:38:29 (INFO): energy_mae: 1.66e+01, forces_mae: 8.61e-04, forces_cosine_similarity: 1.55e-01, forces_magnitude_error: 2.25e-03, energy_forces_within_threshold: 0.00e+00, loss: 1.68e+01, lr: 2.00e-05, epoch: 9.09e-01, step: 1.00e+01
2024-12-12 14:38:32 (INFO): energy_mae: 1.75e+01, forces_mae: 6.67e-04, forces_cosine_similarity: 3.53e-01, forces_magnitude_error: 1.69e-03, energy_forces_within_threshold: 0.00e+00, loss: 1.82e+01, lr: 2.00e-05, epoch: 1.82e+00, step: 2.00e+01
2024-12-12 14:38:36 (INFO): energy_mae: 1.65e+01, forces_mae: 8.29e-04, forces_cosine_similarity: 3.85e-01, forces_magnitude_error: 2.20e-03, energy_forces_within_threshold: 0.00e+00, loss: 1.68e+01, lr: 2.00e-05, epoch: 2.73e+00, step: 3.00e+01
2024-12-12 14:38:39 (INFO): energy_mae: 1.64e+01, forces_mae: 4.72e-04, forces_cosine_similarity: 3.32e-01, forces_magnitude_error: 1.28e-03, energy_forces_within_threshold: 0.00e+00, loss: 1.62e+01, lr: 2.00e-05, epoch: 3.64e+00, step: 4.00e+01
2024-12-12 14:38:42 (INFO): energy_mae: 1.67e+01, forces_mae: 5.07e-04, forces_cosine_similarity: 3.96e-01, forces_magnitude_error: 1.24e-03, energy_forces_within_threshold: 0.00e+00, loss: 1.74e+01, lr: 2.00e-05, epoch: 4.55e+00, step: 5.00e+01
2024-12-12 14:38:45 (INFO): energy_mae: 1.78e+01, forces_mae: 5.62e-04, forces_cosine_similarity: 5.06e-01, forces_magnitude_error: 1.52e-03, energy_forces_within_threshold: 0.00e+00, loss: 1.76e+01, lr: 2.00e-05, epoch: 5.45e+00, step: 6.00e+01
2024-12-12 14:38:47 (INFO): energy_mae: 1.60e+01, forces_mae: 4.84e-04, forces_cosine_similarity: 4.39e-01, forces_magnitude_error: 1.29e-03, energy_forces_within_threshold: 0.00e+00, loss: 1.57e+01, lr: 2.00e-05, epoch: 6.36e+00, step: 7.00e+01
2024-12-12 14:38:49 (INFO): Total time taken: 23.739033460617065
</code></pre><p>Thanks to the FAIRChem team for their valuable feedback on this tutorial!</p><div class="page-footer-meta d-flex flex-column flex-md-row justify-content-between"></div><div class="page-nav d-flex flex-column flex-sm-row"><div class="card w-100"><div class="card-body d-flex"><div class="d-flex flex-column justify-content-center"><svg class="icon icon-tabler icon-tabler-arrow-left" width="20" height="20" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 12h14"/><path d="M5 12l6 6"/><path d="M5 12l6-6"/></svg></div><div class="d-flex flex-column"><div class=text-body-secondary>Prev</div><a href=../../../docs/about/datasets/ class="stretched-link text-reset text-decoration-none">Datasets</a></div></div></div><div class=m-2></div><div class="card text-end w-100"><div class="card-body d-flex justify-content-end"><div class="d-flex flex-column"><div class=text-body-secondary>Next</div><a href=../../../docs/about/citations/ class="stretched-link text-reset text-decoration-none">Citations</a></div><div class="d-flex flex-column justify-content-center"><svg class="icon icon-tabler icon-tabler-arrow-right" width="20" height="20" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 12h14"/><path d="M13 18l6-6"/><path d="M13 6l6 6"/></svg></div></div></div></div></main></div></div></div><footer class="footer text-muted"><div class=container-lg><div class=row><div class="col-lg-8 text-center text-lg-start"><ul class=list-inline></ul></div><div class="col-lg-8 text-center text-lg-end"><ul class=list-inline><li class=list-inline-item></li></ul></div></div></div></footer><script async src=../../../js/app.e30654a9072e12f38c6c4037ec72415478ca137f3dbc3414bf0e4e3f8a3d42d3.js integrity="sha256-4wZUqQcuEvOMbEA37HJBVHjKE389vDQUvw5OP4o9QtM="></script><script async src=../../../js/flexsearch.7b25ae2da7ab3cc745d4f8536e3f914f92ea8b1afad96ab9249c160c35e0648c.js integrity="sha256-eyWuLaerPMdF1PhTbj+RT5Lqixr62Wq5JJwWDDXgZIw="></script><script async src=../../../js/search-modal.0415aa45353ab123a509f6ddc6861549ece898b90872fcf757cd2663041dac96.js integrity="sha256-BBWqRTU6sSOlCfbdxoYVSezomLkIcvz3V80mYwQdrJY="></script></body></html>